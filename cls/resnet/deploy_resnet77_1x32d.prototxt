input: "data"
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 7
    stride: 2
    pad: 3
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1_scale"
  bottom: "conv1"
  top: "conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res1_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "res1_conv1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res1_conv1_bn"
  type: "BatchNorm"
  bottom: "res1_conv1"
  top: "res1_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res1_conv1_scale"
  bottom: "res1_conv1"
  top: "res1_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res1_conv1_relu"
  type: "ReLU"
  bottom: "res1_conv1"
  top: "res1_conv1"
}
layer {
  name: "res1_conv2"
  type: "Convolution"
  bottom: "res1_conv1"
  top: "res1_conv2"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res1_conv2_bn"
  type: "BatchNorm"
  bottom: "res1_conv2"
  top: "res1_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res1_conv2_scale"
  bottom: "res1_conv2"
  top: "res1_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res1_conv2_relu"
  type: "ReLU"
  bottom: "res1_conv2"
  top: "res1_conv2"
}
layer {
  name: "res1_conv3"
  type: "Convolution"
  bottom: "res1_conv2"
  top: "res1_conv3"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res1_conv3_bn"
  type: "BatchNorm"
  bottom: "res1_conv3"
  top: "res1_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res1_conv3_scale"
  bottom: "res1_conv3"
  top: "res1_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res1_match_conv"
  type: "Convolution"
  bottom: "pool1"
  top: "res1_match_conv"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res1_match_conv_bn"
  type: "BatchNorm"
  bottom: "res1_match_conv"
  top: "res1_match_conv"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res1_match_conv_scale"
  bottom: "res1_match_conv"
  top: "res1_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res1_elewise"
  type: "Eltwise"
  bottom: "res1_match_conv"
  bottom: "res1_conv3"
  top: "res1_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res1_elewise_relu"
  type: "ReLU"
  bottom: "res1_elewise"
  top: "res1_elewise"
}
layer {
  name: "res2_conv1"
  type: "Convolution"
  bottom: "res1_elewise"
  top: "res2_conv1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res2_conv1_bn"
  type: "BatchNorm"
  bottom: "res2_conv1"
  top: "res2_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res2_conv1_scale"
  bottom: "res2_conv1"
  top: "res2_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_conv1_relu"
  type: "ReLU"
  bottom: "res2_conv1"
  top: "res2_conv1"
}
layer {
  name: "res2_conv2"
  type: "Convolution"
  bottom: "res2_conv1"
  top: "res2_conv2"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res2_conv2_bn"
  type: "BatchNorm"
  bottom: "res2_conv2"
  top: "res2_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res2_conv2_scale"
  bottom: "res2_conv2"
  top: "res2_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_conv2_relu"
  type: "ReLU"
  bottom: "res2_conv2"
  top: "res2_conv2"
}
layer {
  name: "res2_conv3"
  type: "Convolution"
  bottom: "res2_conv2"
  top: "res2_conv3"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res2_conv3_bn"
  type: "BatchNorm"
  bottom: "res2_conv3"
  top: "res2_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res2_conv3_scale"
  bottom: "res2_conv3"
  top: "res2_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2_elewise"
  type: "Eltwise"
  bottom: "res1_elewise"
  bottom: "res2_conv3"
  top: "res2_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2_elewise_relu"
  type: "ReLU"
  bottom: "res2_elewise"
  top: "res2_elewise"
}
layer {
  name: "res3_conv1"
  type: "Convolution"
  bottom: "res2_elewise"
  top: "res3_conv1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res3_conv1_bn"
  type: "BatchNorm"
  bottom: "res3_conv1"
  top: "res3_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res3_conv1_scale"
  bottom: "res3_conv1"
  top: "res3_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_conv1_relu"
  type: "ReLU"
  bottom: "res3_conv1"
  top: "res3_conv1"
}
layer {
  name: "res3_conv2"
  type: "Convolution"
  bottom: "res3_conv1"
  top: "res3_conv2"
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res3_conv2_bn"
  type: "BatchNorm"
  bottom: "res3_conv2"
  top: "res3_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res3_conv2_scale"
  bottom: "res3_conv2"
  top: "res3_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_conv2_relu"
  type: "ReLU"
  bottom: "res3_conv2"
  top: "res3_conv2"
}
layer {
  name: "res3_conv3"
  type: "Convolution"
  bottom: "res3_conv2"
  top: "res3_conv3"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res3_conv3_bn"
  type: "BatchNorm"
  bottom: "res3_conv3"
  top: "res3_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res3_conv3_scale"
  bottom: "res3_conv3"
  top: "res3_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3_elewise"
  type: "Eltwise"
  bottom: "res2_elewise"
  bottom: "res3_conv3"
  top: "res3_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3_elewise_relu"
  type: "ReLU"
  bottom: "res3_elewise"
  top: "res3_elewise"
}
layer {
  name: "res4_conv1"
  type: "Convolution"
  bottom: "res3_elewise"
  top: "res4_conv1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    pad: 0
  }
}
layer {
  name: "res4_conv1_bn"
  type: "BatchNorm"
  bottom: "res4_conv1"
  top: "res4_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res4_conv1_scale"
  bottom: "res4_conv1"
  top: "res4_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4_conv1_relu"
  type: "ReLU"
  bottom: "res4_conv1"
  top: "res4_conv1"
}
layer {
  name: "res4_conv2"
  type: "Convolution"
  bottom: "res4_conv1"
  top: "res4_conv2"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res4_conv2_bn"
  type: "BatchNorm"
  bottom: "res4_conv2"
  top: "res4_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res4_conv2_scale"
  bottom: "res4_conv2"
  top: "res4_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4_conv2_relu"
  type: "ReLU"
  bottom: "res4_conv2"
  top: "res4_conv2"
}
layer {
  name: "res4_conv3"
  type: "Convolution"
  bottom: "res4_conv2"
  top: "res4_conv3"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res4_conv3_bn"
  type: "BatchNorm"
  bottom: "res4_conv3"
  top: "res4_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res4_conv3_scale"
  bottom: "res4_conv3"
  top: "res4_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4_match_conv"
  type: "Convolution"
  bottom: "res3_elewise"
  top: "res4_match_conv"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 2
    pad: 0
  }
}
layer {
  name: "res4_match_conv_bn"
  type: "BatchNorm"
  bottom: "res4_match_conv"
  top: "res4_match_conv"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res4_match_conv_scale"
  bottom: "res4_match_conv"
  top: "res4_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4_elewise"
  type: "Eltwise"
  bottom: "res4_match_conv"
  bottom: "res4_conv3"
  top: "res4_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4_elewise_relu"
  type: "ReLU"
  bottom: "res4_elewise"
  top: "res4_elewise"
}
layer {
  name: "res5_conv1"
  type: "Convolution"
  bottom: "res4_elewise"
  top: "res5_conv1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res5_conv1_bn"
  type: "BatchNorm"
  bottom: "res5_conv1"
  top: "res5_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res5_conv1_scale"
  bottom: "res5_conv1"
  top: "res5_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5_conv1_relu"
  type: "ReLU"
  bottom: "res5_conv1"
  top: "res5_conv1"
}
layer {
  name: "res5_conv2"
  type: "Convolution"
  bottom: "res5_conv1"
  top: "res5_conv2"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res5_conv2_bn"
  type: "BatchNorm"
  bottom: "res5_conv2"
  top: "res5_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res5_conv2_scale"
  bottom: "res5_conv2"
  top: "res5_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5_conv2_relu"
  type: "ReLU"
  bottom: "res5_conv2"
  top: "res5_conv2"
}
layer {
  name: "res5_conv3"
  type: "Convolution"
  bottom: "res5_conv2"
  top: "res5_conv3"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res5_conv3_bn"
  type: "BatchNorm"
  bottom: "res5_conv3"
  top: "res5_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res5_conv3_scale"
  bottom: "res5_conv3"
  top: "res5_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5_elewise"
  type: "Eltwise"
  bottom: "res4_elewise"
  bottom: "res5_conv3"
  top: "res5_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5_elewise_relu"
  type: "ReLU"
  bottom: "res5_elewise"
  top: "res5_elewise"
}
layer {
  name: "res6_conv1"
  type: "Convolution"
  bottom: "res5_elewise"
  top: "res6_conv1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res6_conv1_bn"
  type: "BatchNorm"
  bottom: "res6_conv1"
  top: "res6_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res6_conv1_scale"
  bottom: "res6_conv1"
  top: "res6_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res6_conv1_relu"
  type: "ReLU"
  bottom: "res6_conv1"
  top: "res6_conv1"
}
layer {
  name: "res6_conv2"
  type: "Convolution"
  bottom: "res6_conv1"
  top: "res6_conv2"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res6_conv2_bn"
  type: "BatchNorm"
  bottom: "res6_conv2"
  top: "res6_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res6_conv2_scale"
  bottom: "res6_conv2"
  top: "res6_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res6_conv2_relu"
  type: "ReLU"
  bottom: "res6_conv2"
  top: "res6_conv2"
}
layer {
  name: "res6_conv3"
  type: "Convolution"
  bottom: "res6_conv2"
  top: "res6_conv3"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res6_conv3_bn"
  type: "BatchNorm"
  bottom: "res6_conv3"
  top: "res6_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res6_conv3_scale"
  bottom: "res6_conv3"
  top: "res6_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res6_elewise"
  type: "Eltwise"
  bottom: "res5_elewise"
  bottom: "res6_conv3"
  top: "res6_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res6_elewise_relu"
  type: "ReLU"
  bottom: "res6_elewise"
  top: "res6_elewise"
}
layer {
  name: "res7_conv1"
  type: "Convolution"
  bottom: "res6_elewise"
  top: "res7_conv1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res7_conv1_bn"
  type: "BatchNorm"
  bottom: "res7_conv1"
  top: "res7_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res7_conv1_scale"
  bottom: "res7_conv1"
  top: "res7_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res7_conv1_relu"
  type: "ReLU"
  bottom: "res7_conv1"
  top: "res7_conv1"
}
layer {
  name: "res7_conv2"
  type: "Convolution"
  bottom: "res7_conv1"
  top: "res7_conv2"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res7_conv2_bn"
  type: "BatchNorm"
  bottom: "res7_conv2"
  top: "res7_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res7_conv2_scale"
  bottom: "res7_conv2"
  top: "res7_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res7_conv2_relu"
  type: "ReLU"
  bottom: "res7_conv2"
  top: "res7_conv2"
}
layer {
  name: "res7_conv3"
  type: "Convolution"
  bottom: "res7_conv2"
  top: "res7_conv3"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res7_conv3_bn"
  type: "BatchNorm"
  bottom: "res7_conv3"
  top: "res7_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res7_conv3_scale"
  bottom: "res7_conv3"
  top: "res7_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res7_elewise"
  type: "Eltwise"
  bottom: "res6_elewise"
  bottom: "res7_conv3"
  top: "res7_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res7_elewise_relu"
  type: "ReLU"
  bottom: "res7_elewise"
  top: "res7_elewise"
}
layer {
  name: "res8_conv1"
  type: "Convolution"
  bottom: "res7_elewise"
  top: "res8_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 2
    pad: 0
  }
}
layer {
  name: "res8_conv1_bn"
  type: "BatchNorm"
  bottom: "res8_conv1"
  top: "res8_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res8_conv1_scale"
  bottom: "res8_conv1"
  top: "res8_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res8_conv1_relu"
  type: "ReLU"
  bottom: "res8_conv1"
  top: "res8_conv1"
}
layer {
  name: "res8_conv2"
  type: "Convolution"
  bottom: "res8_conv1"
  top: "res8_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res8_conv2_bn"
  type: "BatchNorm"
  bottom: "res8_conv2"
  top: "res8_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res8_conv2_scale"
  bottom: "res8_conv2"
  top: "res8_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res8_conv2_relu"
  type: "ReLU"
  bottom: "res8_conv2"
  top: "res8_conv2"
}
layer {
  name: "res8_conv3"
  type: "Convolution"
  bottom: "res8_conv2"
  top: "res8_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res8_conv3_bn"
  type: "BatchNorm"
  bottom: "res8_conv3"
  top: "res8_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res8_conv3_scale"
  bottom: "res8_conv3"
  top: "res8_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res8_match_conv"
  type: "Convolution"
  bottom: "res7_elewise"
  top: "res8_match_conv"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 2
    pad: 0
  }
}
layer {
  name: "res8_match_conv_bn"
  type: "BatchNorm"
  bottom: "res8_match_conv"
  top: "res8_match_conv"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res8_match_conv_scale"
  bottom: "res8_match_conv"
  top: "res8_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res8_elewise"
  type: "Eltwise"
  bottom: "res8_conv3"
  bottom: "res8_match_conv"
  top: "res8_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res8_elewise_relu"
  type: "ReLU"
  bottom: "res8_elewise"
  top: "res8_elewise"
}
layer {
  name: "res9_conv1"
  type: "Convolution"
  bottom: "res8_elewise"
  top: "res9_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res9_conv1_bn"
  type: "BatchNorm"
  bottom: "res9_conv1"
  top: "res9_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res9_conv1_scale"
  bottom: "res9_conv1"
  top: "res9_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res9_conv1_relu"
  type: "ReLU"
  bottom: "res9_conv1"
  top: "res9_conv1"
}
layer {
  name: "res9_conv2"
  type: "Convolution"
  bottom: "res9_conv1"
  top: "res9_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res9_conv2_bn"
  type: "BatchNorm"
  bottom: "res9_conv2"
  top: "res9_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res9_conv2_scale"
  bottom: "res9_conv2"
  top: "res9_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res9_conv2_relu"
  type: "ReLU"
  bottom: "res9_conv2"
  top: "res9_conv2"
}
layer {
  name: "res9_conv3"
  type: "Convolution"
  bottom: "res9_conv2"
  top: "res9_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res9_conv3_bn"
  type: "BatchNorm"
  bottom: "res9_conv3"
  top: "res9_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res9_conv3_scale"
  bottom: "res9_conv3"
  top: "res9_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res9_elewise"
  type: "Eltwise"
  bottom: "res8_elewise"
  bottom: "res9_conv3"
  top: "res9_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res9_elewise_relu"
  type: "ReLU"
  bottom: "res9_elewise"
  top: "res9_elewise"
}
layer {
  name: "res10_conv1"
  type: "Convolution"
  bottom: "res9_elewise"
  top: "res10_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res10_conv1_bn"
  type: "BatchNorm"
  bottom: "res10_conv1"
  top: "res10_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res10_conv1_scale"
  bottom: "res10_conv1"
  top: "res10_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res10_conv1_relu"
  type: "ReLU"
  bottom: "res10_conv1"
  top: "res10_conv1"
}
layer {
  name: "res10_conv2"
  type: "Convolution"
  bottom: "res10_conv1"
  top: "res10_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res10_conv2_bn"
  type: "BatchNorm"
  bottom: "res10_conv2"
  top: "res10_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res10_conv2_scale"
  bottom: "res10_conv2"
  top: "res10_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res10_conv2_relu"
  type: "ReLU"
  bottom: "res10_conv2"
  top: "res10_conv2"
}
layer {
  name: "res10_conv3"
  type: "Convolution"
  bottom: "res10_conv2"
  top: "res10_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res10_conv3_bn"
  type: "BatchNorm"
  bottom: "res10_conv3"
  top: "res10_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res10_conv3_scale"
  bottom: "res10_conv3"
  top: "res10_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res10_elewise"
  type: "Eltwise"
  bottom: "res9_elewise"
  bottom: "res10_conv3"
  top: "res10_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res10_elewise_relu"
  type: "ReLU"
  bottom: "res10_elewise"
  top: "res10_elewise"
}
layer {
  name: "res11_conv1"
  type: "Convolution"
  bottom: "res10_elewise"
  top: "res11_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res11_conv1_bn"
  type: "BatchNorm"
  bottom: "res11_conv1"
  top: "res11_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res11_conv1_scale"
  bottom: "res11_conv1"
  top: "res11_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res11_conv1_relu"
  type: "ReLU"
  bottom: "res11_conv1"
  top: "res11_conv1"
}
layer {
  name: "res11_conv2"
  type: "Convolution"
  bottom: "res11_conv1"
  top: "res11_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res11_conv2_bn"
  type: "BatchNorm"
  bottom: "res11_conv2"
  top: "res11_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res11_conv2_scale"
  bottom: "res11_conv2"
  top: "res11_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res11_conv2_relu"
  type: "ReLU"
  bottom: "res11_conv2"
  top: "res11_conv2"
}
layer {
  name: "res11_conv3"
  type: "Convolution"
  bottom: "res11_conv2"
  top: "res11_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res11_conv3_bn"
  type: "BatchNorm"
  bottom: "res11_conv3"
  top: "res11_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res11_conv3_scale"
  bottom: "res11_conv3"
  top: "res11_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res11_elewise"
  type: "Eltwise"
  bottom: "res10_elewise"
  bottom: "res11_conv3"
  top: "res11_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res11_elewise_relu"
  type: "ReLU"
  bottom: "res11_elewise"
  top: "res11_elewise"
}
layer {
  name: "res12_conv1"
  type: "Convolution"
  bottom: "res11_elewise"
  top: "res12_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res12_conv1_bn"
  type: "BatchNorm"
  bottom: "res12_conv1"
  top: "res12_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res12_conv1_scale"
  bottom: "res12_conv1"
  top: "res12_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res12_conv1_relu"
  type: "ReLU"
  bottom: "res12_conv1"
  top: "res12_conv1"
}
layer {
  name: "res12_conv2"
  type: "Convolution"
  bottom: "res12_conv1"
  top: "res12_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res12_conv2_bn"
  type: "BatchNorm"
  bottom: "res12_conv2"
  top: "res12_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res12_conv2_scale"
  bottom: "res12_conv2"
  top: "res12_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res12_conv2_relu"
  type: "ReLU"
  bottom: "res12_conv2"
  top: "res12_conv2"
}
layer {
  name: "res12_conv3"
  type: "Convolution"
  bottom: "res12_conv2"
  top: "res12_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res12_conv3_bn"
  type: "BatchNorm"
  bottom: "res12_conv3"
  top: "res12_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res12_conv3_scale"
  bottom: "res12_conv3"
  top: "res12_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res12_elewise"
  type: "Eltwise"
  bottom: "res11_elewise"
  bottom: "res12_conv3"
  top: "res12_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res12_elewise_relu"
  type: "ReLU"
  bottom: "res12_elewise"
  top: "res12_elewise"
}
layer {
  name: "res13_conv1"
  type: "Convolution"
  bottom: "res12_elewise"
  top: "res13_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res13_conv1_bn"
  type: "BatchNorm"
  bottom: "res13_conv1"
  top: "res13_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res13_conv1_scale"
  bottom: "res13_conv1"
  top: "res13_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res13_conv1_relu"
  type: "ReLU"
  bottom: "res13_conv1"
  top: "res13_conv1"
}
layer {
  name: "res13_conv2"
  type: "Convolution"
  bottom: "res13_conv1"
  top: "res13_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res13_conv2_bn"
  type: "BatchNorm"
  bottom: "res13_conv2"
  top: "res13_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res13_conv2_scale"
  bottom: "res13_conv2"
  top: "res13_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res13_conv2_relu"
  type: "ReLU"
  bottom: "res13_conv2"
  top: "res13_conv2"
}
layer {
  name: "res13_conv3"
  type: "Convolution"
  bottom: "res13_conv2"
  top: "res13_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res13_conv3_bn"
  type: "BatchNorm"
  bottom: "res13_conv3"
  top: "res13_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res13_conv3_scale"
  bottom: "res13_conv3"
  top: "res13_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res13_elewise"
  type: "Eltwise"
  bottom: "res12_elewise"
  bottom: "res13_conv3"
  top: "res13_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res13_elewise_relu"
  type: "ReLU"
  bottom: "res13_elewise"
  top: "res13_elewise"
}
layer {
  name: "res14_conv1"
  type: "Convolution"
  bottom: "res13_elewise"
  top: "res14_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res14_conv1_bn"
  type: "BatchNorm"
  bottom: "res14_conv1"
  top: "res14_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res14_conv1_scale"
  bottom: "res14_conv1"
  top: "res14_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res14_conv1_relu"
  type: "ReLU"
  bottom: "res14_conv1"
  top: "res14_conv1"
}
layer {
  name: "res14_conv2"
  type: "Convolution"
  bottom: "res14_conv1"
  top: "res14_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res14_conv2_bn"
  type: "BatchNorm"
  bottom: "res14_conv2"
  top: "res14_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res14_conv2_scale"
  bottom: "res14_conv2"
  top: "res14_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res14_conv2_relu"
  type: "ReLU"
  bottom: "res14_conv2"
  top: "res14_conv2"
}
layer {
  name: "res14_conv3"
  type: "Convolution"
  bottom: "res14_conv2"
  top: "res14_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res14_conv3_bn"
  type: "BatchNorm"
  bottom: "res14_conv3"
  top: "res14_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res14_conv3_scale"
  bottom: "res14_conv3"
  top: "res14_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res14_elewise"
  type: "Eltwise"
  bottom: "res13_elewise"
  bottom: "res14_conv3"
  top: "res14_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res14_elewise_relu"
  type: "ReLU"
  bottom: "res14_elewise"
  top: "res14_elewise"
}
layer {
  name: "res15_conv1"
  type: "Convolution"
  bottom: "res14_elewise"
  top: "res15_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res15_conv1_bn"
  type: "BatchNorm"
  bottom: "res15_conv1"
  top: "res15_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res15_conv1_scale"
  bottom: "res15_conv1"
  top: "res15_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res15_conv1_relu"
  type: "ReLU"
  bottom: "res15_conv1"
  top: "res15_conv1"
}
layer {
  name: "res15_conv2"
  type: "Convolution"
  bottom: "res15_conv1"
  top: "res15_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res15_conv2_bn"
  type: "BatchNorm"
  bottom: "res15_conv2"
  top: "res15_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res15_conv2_scale"
  bottom: "res15_conv2"
  top: "res15_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res15_conv2_relu"
  type: "ReLU"
  bottom: "res15_conv2"
  top: "res15_conv2"
}
layer {
  name: "res15_conv3"
  type: "Convolution"
  bottom: "res15_conv2"
  top: "res15_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res15_conv3_bn"
  type: "BatchNorm"
  bottom: "res15_conv3"
  top: "res15_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res15_conv3_scale"
  bottom: "res15_conv3"
  top: "res15_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res15_elewise"
  type: "Eltwise"
  bottom: "res14_elewise"
  bottom: "res15_conv3"
  top: "res15_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res15_elewise_relu"
  type: "ReLU"
  bottom: "res15_elewise"
  top: "res15_elewise"
}
layer {
  name: "res16_conv1"
  type: "Convolution"
  bottom: "res15_elewise"
  top: "res16_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res16_conv1_bn"
  type: "BatchNorm"
  bottom: "res16_conv1"
  top: "res16_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res16_conv1_scale"
  bottom: "res16_conv1"
  top: "res16_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res16_conv1_relu"
  type: "ReLU"
  bottom: "res16_conv1"
  top: "res16_conv1"
}
layer {
  name: "res16_conv2"
  type: "Convolution"
  bottom: "res16_conv1"
  top: "res16_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res16_conv2_bn"
  type: "BatchNorm"
  bottom: "res16_conv2"
  top: "res16_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res16_conv2_scale"
  bottom: "res16_conv2"
  top: "res16_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res16_conv2_relu"
  type: "ReLU"
  bottom: "res16_conv2"
  top: "res16_conv2"
}
layer {
  name: "res16_conv3"
  type: "Convolution"
  bottom: "res16_conv2"
  top: "res16_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res16_conv3_bn"
  type: "BatchNorm"
  bottom: "res16_conv3"
  top: "res16_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res16_conv3_scale"
  bottom: "res16_conv3"
  top: "res16_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res16_elewise"
  type: "Eltwise"
  bottom: "res15_elewise"
  bottom: "res16_conv3"
  top: "res16_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res16_elewise_relu"
  type: "ReLU"
  bottom: "res16_elewise"
  top: "res16_elewise"
}
layer {
  name: "res17_conv1"
  type: "Convolution"
  bottom: "res16_elewise"
  top: "res17_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res17_conv1_bn"
  type: "BatchNorm"
  bottom: "res17_conv1"
  top: "res17_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res17_conv1_scale"
  bottom: "res17_conv1"
  top: "res17_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res17_conv1_relu"
  type: "ReLU"
  bottom: "res17_conv1"
  top: "res17_conv1"
}
layer {
  name: "res17_conv2"
  type: "Convolution"
  bottom: "res17_conv1"
  top: "res17_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res17_conv2_bn"
  type: "BatchNorm"
  bottom: "res17_conv2"
  top: "res17_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res17_conv2_scale"
  bottom: "res17_conv2"
  top: "res17_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res17_conv2_relu"
  type: "ReLU"
  bottom: "res17_conv2"
  top: "res17_conv2"
}
layer {
  name: "res17_conv3"
  type: "Convolution"
  bottom: "res17_conv2"
  top: "res17_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res17_conv3_bn"
  type: "BatchNorm"
  bottom: "res17_conv3"
  top: "res17_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res17_conv3_scale"
  bottom: "res17_conv3"
  top: "res17_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res17_elewise"
  type: "Eltwise"
  bottom: "res16_elewise"
  bottom: "res17_conv3"
  top: "res17_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res17_elewise_relu"
  type: "ReLU"
  bottom: "res17_elewise"
  top: "res17_elewise"
}
layer {
  name: "res18_conv1"
  type: "Convolution"
  bottom: "res17_elewise"
  top: "res18_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res18_conv1_bn"
  type: "BatchNorm"
  bottom: "res18_conv1"
  top: "res18_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res18_conv1_scale"
  bottom: "res18_conv1"
  top: "res18_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res18_conv1_relu"
  type: "ReLU"
  bottom: "res18_conv1"
  top: "res18_conv1"
}
layer {
  name: "res18_conv2"
  type: "Convolution"
  bottom: "res18_conv1"
  top: "res18_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res18_conv2_bn"
  type: "BatchNorm"
  bottom: "res18_conv2"
  top: "res18_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res18_conv2_scale"
  bottom: "res18_conv2"
  top: "res18_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res18_conv2_relu"
  type: "ReLU"
  bottom: "res18_conv2"
  top: "res18_conv2"
}
layer {
  name: "res18_conv3"
  type: "Convolution"
  bottom: "res18_conv2"
  top: "res18_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res18_conv3_bn"
  type: "BatchNorm"
  bottom: "res18_conv3"
  top: "res18_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res18_conv3_scale"
  bottom: "res18_conv3"
  top: "res18_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res18_elewise"
  type: "Eltwise"
  bottom: "res17_elewise"
  bottom: "res18_conv3"
  top: "res18_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res18_elewise_relu"
  type: "ReLU"
  bottom: "res18_elewise"
  top: "res18_elewise"
}
layer {
  name: "res19_conv1"
  type: "Convolution"
  bottom: "res18_elewise"
  top: "res19_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res19_conv1_bn"
  type: "BatchNorm"
  bottom: "res19_conv1"
  top: "res19_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res19_conv1_scale"
  bottom: "res19_conv1"
  top: "res19_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res19_conv1_relu"
  type: "ReLU"
  bottom: "res19_conv1"
  top: "res19_conv1"
}
layer {
  name: "res19_conv2"
  type: "Convolution"
  bottom: "res19_conv1"
  top: "res19_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res19_conv2_bn"
  type: "BatchNorm"
  bottom: "res19_conv2"
  top: "res19_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res19_conv2_scale"
  bottom: "res19_conv2"
  top: "res19_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res19_conv2_relu"
  type: "ReLU"
  bottom: "res19_conv2"
  top: "res19_conv2"
}
layer {
  name: "res19_conv3"
  type: "Convolution"
  bottom: "res19_conv2"
  top: "res19_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res19_conv3_bn"
  type: "BatchNorm"
  bottom: "res19_conv3"
  top: "res19_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res19_conv3_scale"
  bottom: "res19_conv3"
  top: "res19_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res19_elewise"
  type: "Eltwise"
  bottom: "res18_elewise"
  bottom: "res19_conv3"
  top: "res19_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res19_elewise_relu"
  type: "ReLU"
  bottom: "res19_elewise"
  top: "res19_elewise"
}
layer {
  name: "res20_conv1"
  type: "Convolution"
  bottom: "res19_elewise"
  top: "res20_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res20_conv1_bn"
  type: "BatchNorm"
  bottom: "res20_conv1"
  top: "res20_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res20_conv1_scale"
  bottom: "res20_conv1"
  top: "res20_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res20_conv1_relu"
  type: "ReLU"
  bottom: "res20_conv1"
  top: "res20_conv1"
}
layer {
  name: "res20_conv2"
  type: "Convolution"
  bottom: "res20_conv1"
  top: "res20_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res20_conv2_bn"
  type: "BatchNorm"
  bottom: "res20_conv2"
  top: "res20_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res20_conv2_scale"
  bottom: "res20_conv2"
  top: "res20_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res20_conv2_relu"
  type: "ReLU"
  bottom: "res20_conv2"
  top: "res20_conv2"
}
layer {
  name: "res20_conv3"
  type: "Convolution"
  bottom: "res20_conv2"
  top: "res20_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res20_conv3_bn"
  type: "BatchNorm"
  bottom: "res20_conv3"
  top: "res20_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res20_conv3_scale"
  bottom: "res20_conv3"
  top: "res20_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res20_elewise"
  type: "Eltwise"
  bottom: "res19_elewise"
  bottom: "res20_conv3"
  top: "res20_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res20_elewise_relu"
  type: "ReLU"
  bottom: "res20_elewise"
  top: "res20_elewise"
}
layer {
  name: "res21_conv1"
  type: "Convolution"
  bottom: "res20_elewise"
  top: "res21_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res21_conv1_bn"
  type: "BatchNorm"
  bottom: "res21_conv1"
  top: "res21_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res21_conv1_scale"
  bottom: "res21_conv1"
  top: "res21_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res21_conv1_relu"
  type: "ReLU"
  bottom: "res21_conv1"
  top: "res21_conv1"
}
layer {
  name: "res21_conv2"
  type: "Convolution"
  bottom: "res21_conv1"
  top: "res21_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res21_conv2_bn"
  type: "BatchNorm"
  bottom: "res21_conv2"
  top: "res21_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res21_conv2_scale"
  bottom: "res21_conv2"
  top: "res21_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res21_conv2_relu"
  type: "ReLU"
  bottom: "res21_conv2"
  top: "res21_conv2"
}
layer {
  name: "res21_conv3"
  type: "Convolution"
  bottom: "res21_conv2"
  top: "res21_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res21_conv3_bn"
  type: "BatchNorm"
  bottom: "res21_conv3"
  top: "res21_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res21_conv3_scale"
  bottom: "res21_conv3"
  top: "res21_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res21_elewise"
  type: "Eltwise"
  bottom: "res20_elewise"
  bottom: "res21_conv3"
  top: "res21_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res21_elewise_relu"
  type: "ReLU"
  bottom: "res21_elewise"
  top: "res21_elewise"
}
layer {
  name: "res22_conv1"
  type: "Convolution"
  bottom: "res21_elewise"
  top: "res22_conv1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res22_conv1_bn"
  type: "BatchNorm"
  bottom: "res22_conv1"
  top: "res22_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res22_conv1_scale"
  bottom: "res22_conv1"
  top: "res22_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res22_conv1_relu"
  type: "ReLU"
  bottom: "res22_conv1"
  top: "res22_conv1"
}
layer {
  name: "res22_conv2"
  type: "Convolution"
  bottom: "res22_conv1"
  top: "res22_conv2"
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res22_conv2_bn"
  type: "BatchNorm"
  bottom: "res22_conv2"
  top: "res22_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res22_conv2_scale"
  bottom: "res22_conv2"
  top: "res22_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res22_conv2_relu"
  type: "ReLU"
  bottom: "res22_conv2"
  top: "res22_conv2"
}
layer {
  name: "res22_conv3"
  type: "Convolution"
  bottom: "res22_conv2"
  top: "res22_conv3"
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res22_conv3_bn"
  type: "BatchNorm"
  bottom: "res22_conv3"
  top: "res22_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res22_conv3_scale"
  bottom: "res22_conv3"
  top: "res22_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res22_elewise"
  type: "Eltwise"
  bottom: "res21_elewise"
  bottom: "res22_conv3"
  top: "res22_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res22_elewise_relu"
  type: "ReLU"
  bottom: "res22_elewise"
  top: "res22_elewise"
}
layer {
  name: "res23_conv1"
  type: "Convolution"
  bottom: "res22_elewise"
  top: "res23_conv1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 2
    pad: 0
  }
}
layer {
  name: "res23_conv1_bn"
  type: "BatchNorm"
  bottom: "res23_conv1"
  top: "res23_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res23_conv1_scale"
  bottom: "res23_conv1"
  top: "res23_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res23_conv1_relu"
  type: "ReLU"
  bottom: "res23_conv1"
  top: "res23_conv1"
}
layer {
  name: "res23_conv2"
  type: "Convolution"
  bottom: "res23_conv1"
  top: "res23_conv2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res23_conv2_bn"
  type: "BatchNorm"
  bottom: "res23_conv2"
  top: "res23_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res23_conv2_scale"
  bottom: "res23_conv2"
  top: "res23_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res23_conv2_relu"
  type: "ReLU"
  bottom: "res23_conv2"
  top: "res23_conv2"
}
layer {
  name: "res23_conv3"
  type: "Convolution"
  bottom: "res23_conv2"
  top: "res23_conv3"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res23_conv3_bn"
  type: "BatchNorm"
  bottom: "res23_conv3"
  top: "res23_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res23_conv3_scale"
  bottom: "res23_conv3"
  top: "res23_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res23_match_conv"
  type: "Convolution"
  bottom: "res22_elewise"
  top: "res23_match_conv"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 2
    pad: 0
  }
}
layer {
  name: "res23_match_conv_bn"
  type: "BatchNorm"
  bottom: "res23_match_conv"
  top: "res23_match_conv"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res23_match_conv_scale"
  bottom: "res23_match_conv"
  top: "res23_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res23_elewise"
  type: "Eltwise"
  bottom: "res23_match_conv"
  bottom: "res23_conv3"
  top: "res23_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res23_elewise_relu"
  type: "ReLU"
  bottom: "res23_elewise"
  top: "res23_elewise"
}
layer {
  name: "res24_conv1"
  type: "Convolution"
  bottom: "res23_elewise"
  top: "res24_conv1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res24_conv1_bn"
  type: "BatchNorm"
  bottom: "res24_conv1"
  top: "res24_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res24_conv1_scale"
  bottom: "res24_conv1"
  top: "res24_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res24_conv1_relu"
  type: "ReLU"
  bottom: "res24_conv1"
  top: "res24_conv1"
}
layer {
  name: "res24_conv2"
  type: "Convolution"
  bottom: "res24_conv1"
  top: "res24_conv2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res24_conv2_bn"
  type: "BatchNorm"
  bottom: "res24_conv2"
  top: "res24_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res24_conv2_scale"
  bottom: "res24_conv2"
  top: "res24_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res24_conv2_relu"
  type: "ReLU"
  bottom: "res24_conv2"
  top: "res24_conv2"
}
layer {
  name: "res24_conv3"
  type: "Convolution"
  bottom: "res24_conv2"
  top: "res24_conv3"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res24_conv3_bn"
  type: "BatchNorm"
  bottom: "res24_conv3"
  top: "res24_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res24_conv3_scale"
  bottom: "res24_conv3"
  top: "res24_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res24_elewise"
  type: "Eltwise"
  bottom: "res23_elewise"
  bottom: "res24_conv3"
  top: "res24_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res24_elewise_relu"
  type: "ReLU"
  bottom: "res24_elewise"
  top: "res24_elewise"
}
layer {
  name: "res25_conv1"
  type: "Convolution"
  bottom: "res24_elewise"
  top: "res25_conv1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res25_conv1_bn"
  type: "BatchNorm"
  bottom: "res25_conv1"
  top: "res25_conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res25_conv1_scale"
  bottom: "res25_conv1"
  top: "res25_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res25_conv1_relu"
  type: "ReLU"
  bottom: "res25_conv1"
  top: "res25_conv1"
}
layer {
  name: "res25_conv2"
  type: "Convolution"
  bottom: "res25_conv1"
  top: "res25_conv2"
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "res25_conv2_bn"
  type: "BatchNorm"
  bottom: "res25_conv2"
  top: "res25_conv2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res25_conv2_scale"
  bottom: "res25_conv2"
  top: "res25_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res25_conv2_relu"
  type: "ReLU"
  bottom: "res25_conv2"
  top: "res25_conv2"
}
layer {
  name: "res25_conv3"
  type: "Convolution"
  bottom: "res25_conv2"
  top: "res25_conv3"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
  }
}
layer {
  name: "res25_conv3_bn"
  type: "BatchNorm"
  bottom: "res25_conv3"
  top: "res25_conv3"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "res25_conv3_scale"
  bottom: "res25_conv3"
  top: "res25_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res25_elewise"
  type: "Eltwise"
  bottom: "res24_elewise"
  bottom: "res25_conv3"
  top: "res25_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res25_elewise_relu"
  type: "ReLU"
  bottom: "res25_elewise"
  top: "res25_elewise"
}
layer {
  name: "pool_ave"
  type: "Pooling"
  bottom: "res25_elewise"
  top: "pool_ave"
  pooling_param {
    global_pooling : true
    pool: AVE
  }
}
layer {
  name: "classifier"
  type: "InnerProduct"
  bottom: "pool_ave"
  top: "classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "classifier"
  top: "prob"
}



